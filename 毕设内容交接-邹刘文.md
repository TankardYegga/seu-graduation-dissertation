## 1. 代码介绍

### 1.1 服务器：

10.201.0.149
账号密码：zouliuwen/zlw654321

### 1.2 数据存储位置：

/mnt/no2/zlw/GraduationThesis/AllDatasets/Breast_US_Seg_Formal_Whole_W_NO_NORMAL_0.75_0.05_0.2_20240302_20:28:27

### 1.3 完整的代码存储位置：

/mnt/no2/zlw/GraduationThesis/nerve_segmentation/my_segmentation_code

### 1.4 模型训练结果存储位置：

/mnt/no2/zlw/GraduationThesis/nerve_segmentation/my_segmentation_code_results

## 2. 第四章模型代码

### 2.1 边缘扩散单元的代码

~~~python
class DiffusionUnit(nn.Module):

    def __init__(self, iter_nums = 1, same_g = True, in_channels = 512, out_channels = 512, is_cuda = True):
        

        super(DiffusionUnit, self).__init__()

        self.iter_nums = iter_nums
        self.same_g = same_g
        self.is_cuda = is_cuda

        # 迭代多次，有两种选择
        # 一种选择是每次迭代都使用一样的g
        # 另一种选择是每次迭代都使用不一样的g
        if self.same_g:
            g_lists = []
            diffusion_function = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)
            diffusion_bn = nn.BatchNorm2d(num_features=out_channels)
            diffusion_relu = nn.ReLU(inplace=True)
            g_lists.append(diffusion_function)
            g_lists.append(diffusion_bn)
            g_lists.append(diffusion_relu)
            self.g_lists = nn.Sequential(*g_lists).cuda(device=device_id)

        else:
            
            g_lists = []
            for i in range(iter_nums):
                g_single_list = []
                diffusion_function = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)
                diffusion_bn = nn.BatchNorm2d(num_features=out_channels)
                diffusion_relu = nn.ReLU(inplace=True)
                g_single_list.append(diffusion_function)
                g_single_list.append(diffusion_bn)
                g_single_list.append(diffusion_relu)
                single_g = nn.Sequential(*g_single_list).cuda(device_id)
                # single_g = nn.Sequential(*g_single_list)
                g_lists.append(single_g)
            self.g_lists = g_lists


    def forward(self,x):
        # 输入的特征图是 (B, C, H, W)
        
        # 迭代更新特征图中每个像素点的特征

        # 对于每个像素点要找到其周围的8个邻居像素点
        # 边界上的点不用单独处理，只要对应邻居的坐标不在合理范围内就可以自动排除
        # 只需要通过邻接矩阵来实现
        H = x.shape[-2]
        W = x.shape[-1]
        pixels_num = H * W

        if self.is_cuda:
            adj_arr = torch.zeros(pixels_num, pixels_num).cuda(device_id)
        else:
            adj_arr = torch.zeros(pixels_num, pixels_num)

        adj_degree = []

        for i in range(H):
            for j in range(W):
                cur_pos  = i * W + j
                possible_neigbors_x = [i - 1, i - 1, i - 1, i, i, i + 1, i + 1, i + 1]
                possible_neigbors_y = [j - 1, j, j + 1, j - 1, j + 1, j - 1, j, j + 1]
                count = 0
                for idx in range(len(possible_neigbors_x)):
                    x_isvalid = possible_neigbors_x[idx] >= 0 and possible_neigbors_x[idx] <= H - 1
                    y_isvalid = possible_neigbors_y[idx] >= 0 and possible_neigbors_y[idx] <= W - 1
                    if x_isvalid and y_isvalid:
                        count += 1
                        valid_neighbor_pos = possible_neigbors_x[idx] * W + possible_neigbors_y[idx]
                        adj_arr[cur_pos][valid_neighbor_pos] = 1
                adj_arr[cur_pos][cur_pos] = -1 * count
                adj_degree.append([count])

        # print("x.device = ")
        # print(x.device)

        adj_degree = torch.Tensor(adj_degree)
        if self.is_cuda:
            adj_degree = adj_degree.cuda(device_id)
        # print("adj_degree = ")
        # print(adj_degree.device)

        # (B, C, H, W) => (B, H * W, C)
        x = x.view(x.shape[0], H * W, -1)

        if self.same_g:
            for i in range(self.iter_nums):

                # print("current i is:" + str(i))

                residual_x = x.clone()
                # (H * W, H * W) * (B, H * W, C)　＝＞ (B, H * W, C)

                x = torch.matmul(adj_arr, x)

                x = x.view(x.shape[0], -1, H, W)  # (B, H * W, C) => (B, C, H, W)

                x = self.g_lists(x)

                x = x.view(x.shape[0], H * W, -1) # (B, C, H, W) => (B, H * W, C)

                # normalized 
                x = (1 / adj_degree) * x

                # residual connection (B, H * W, C) + (B, H * W, C) = (B, H * W, C)
                x = x + residual_x

        else:
             for i in range(self.iter_nums):

                # print("current i is:" + str(i))

                residual_x = x.clone()
                # (H * W, H * W) * (B, H * W, C)　＝＞ (B, H * W, C)
                x = torch.matmul(adj_arr, x)

                x = x.view(x.shape[0], -1, H, W)  # (B, H * W, C) => (B, C, H, W)


                # print("x device is:")
                # print(x.device)

                x = self.g_lists[i](x)

                x = x.view(x.shape[0], H * W, -1) # (B, C, H, W) => (B, H * W, C)

                # normalized 
                x = (1 / adj_degree) * x

                # residual connection (B, H * W, C) + (B, H * W, C) = (B, H * W, C)
                x = x + residual_x

        
        # (B, H * W, C) =》（B, C, H, W）
        reshaped_back_x = x.view(x.shape[0], -1, H, W)

        return reshaped_back_x
~~~

~~~python
class up_conv_with_DiffusionUnit(nn.Module):
    """
    Up Convolution Block
    """
    def __init__(self, in_ch, out_ch, same_g = True, iter_nums = 1, is_cuda = True):
        super(up_conv_with_DiffusionUnit, self).__init__()
        self.up = nn.Sequential(
            nn.Upsample(scale_factor=2),
            DiffusionUnit(iter_nums=iter_nums, same_g=same_g, in_channels=in_ch, out_channels=in_ch, is_cuda = is_cuda),
            nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=1, padding=0, bias=True),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        x = self.up(x)
        return x
~~~

### 2.2 Unet + 边缘扩散单元的代码(依次是从底往上的四个解码器位置分别添加该单元)

~~~python
if model_name == 'UNetWithTraditionDiffusion2':
        model = UNetWithTraditionDiffusion2(in_ch=3, out_ch=1, same_g = False, iter_nums = 2)
        return model
    
if model_name == 'UNetWithTraditionDiffusion3':
        model = UNetWithTraditionDiffusion3(in_ch=3, out_ch=1, same_g = False, iter_nums = 2)
        return model

if model_name == 'UNetWithTraditionDiffusion4':
        model = UNetWithTraditionDiffusion4(in_ch=3, out_ch=1, same_g = False, iter_nums = 2)
        return model

if model_name == 'UNetWithTraditionDiffusion5':
        model = UNetWithTraditionDiffusion5(in_ch=3, out_ch=1, same_g = False, iter_nums = 2)
        return model
~~~

~~~python
class UNetWithTraditionDiffusion2(nn.Module):
    """
    UNet - Basic Implementation
    Paper : https://arxiv.org/abs/1505.04597
    """
    def __init__(self, in_ch=3, out_ch=1, same_g = True, iter_nums = 2):
        super(UNetWithTraditionDiffusion2, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]
        # print("filters: ", filters)
        
        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.Conv1 = conv_block(in_ch, filters[0])
        self.Conv2 = conv_block(filters[0], filters[1])
        self.Conv3 = conv_block(filters[1], filters[2])
        self.Conv4 = conv_block(filters[2], filters[3])
        self.Conv5 = conv_block(filters[3], filters[4])

        self.Up5 = up_conv_with_DiffusionUnit(filters[4], filters[3], same_g = same_g, iter_nums = iter_nums)
        self.Up_conv5 = conv_block(filters[4], filters[3])

        self.Up4 = up_conv(filters[3], filters[2])
        self.Up_conv4 = conv_block(filters[3], filters[2])

        self.Up3 = up_conv(filters[2], filters[1])
        self.Up_conv3 = conv_block(filters[2], filters[1])

        self.Up2 = up_conv(filters[1], filters[0])
        self.Up_conv2 = conv_block(filters[1], filters[0])

        self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)


    def forward(self, x):

        e1 = self.Conv1(x)

        e2 = self.Maxpool1(e1)
        e2 = self.Conv2(e2)

        e3 = self.Maxpool2(e2)
        e3 = self.Conv3(e3)

        e4 = self.Maxpool3(e3)
        e4 = self.Conv4(e4)

        e5 = self.Maxpool4(e4)
        e5 = self.Conv5(e5)

        # print("e5 shape:", e5.shape)

        d5 = self.Up5(e5)
        d5 = torch.cat((e4, d5), dim=1)

        d5 = self.Up_conv5(d5)

        d4 = self.Up4(d5)
        d4 = torch.cat((e3, d4), dim=1)
        d4 = self.Up_conv4(d4)

        d3 = self.Up3(d4)
        d3 = torch.cat((e2, d3), dim=1)
        d3 = self.Up_conv3(d3)

        d2 = self.Up2(d3)
        d2 = torch.cat((e1, d2), dim=1)
        d2 = self.Up_conv2(d2)
        out = self.Conv(d2)


        return torch.sigmoid(out)
  
class UNetWithTraditionDiffusion3(nn.Module):
    """
    UNet - Basic Implementation
    Paper : https://arxiv.org/abs/1505.04597
    """
    def __init__(self, in_ch=3, out_ch=1, same_g = True, iter_nums = 2):
        super(UNetWithTraditionDiffusion3, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]
        # print("filters: ", filters)
        
        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.Conv1 = conv_block(in_ch, filters[0])
        self.Conv2 = conv_block(filters[0], filters[1])
        self.Conv3 = conv_block(filters[1], filters[2])
        self.Conv4 = conv_block(filters[2], filters[3])
        self.Conv5 = conv_block(filters[3], filters[4])

        self.Up5 = up_conv(filters[4], filters[3])
        self.Up_conv5 = conv_block(filters[4], filters[3])

        self.Up4 = up_conv_with_DiffusionUnit(filters[3], filters[2], same_g = same_g, iter_nums = iter_nums)
        self.Up_conv4 = conv_block(filters[3], filters[2])

        self.Up3 = up_conv(filters[2], filters[1])
        self.Up_conv3 = conv_block(filters[2], filters[1])

        self.Up2 = up_conv(filters[1], filters[0])
        self.Up_conv2 = conv_block(filters[1], filters[0])

        self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)


    def forward(self, x):

        e1 = self.Conv1(x)

        e2 = self.Maxpool1(e1)
        e2 = self.Conv2(e2)

        e3 = self.Maxpool2(e2)
        e3 = self.Conv3(e3)

        e4 = self.Maxpool3(e3)
        e4 = self.Conv4(e4)

        e5 = self.Maxpool4(e4)
        e5 = self.Conv5(e5)

        # print("e5 shape:", e5.shape)

        d5 = self.Up5(e5)
        d5 = torch.cat((e4, d5), dim=1)

        d5 = self.Up_conv5(d5)

        d4 = self.Up4(d5)
        d4 = torch.cat((e3, d4), dim=1)
        d4 = self.Up_conv4(d4)

        d3 = self.Up3(d4)
        d3 = torch.cat((e2, d3), dim=1)
        d3 = self.Up_conv3(d3)

        d2 = self.Up2(d3)
        d2 = torch.cat((e1, d2), dim=1)
        d2 = self.Up_conv2(d2)
        out = self.Conv(d2)


        return torch.sigmoid(out)
    

class UNetWithTraditionDiffusion4(nn.Module):
    """
    UNet - Basic Implementation
    Paper : https://arxiv.org/abs/1505.04597
    """
    def __init__(self, in_ch=3, out_ch=1, same_g = True, iter_nums = 2):
        super(UNetWithTraditionDiffusion4, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]
        # print("filters: ", filters)
        
        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.Conv1 = conv_block(in_ch, filters[0])
        self.Conv2 = conv_block(filters[0], filters[1])
        self.Conv3 = conv_block(filters[1], filters[2])
        self.Conv4 = conv_block(filters[2], filters[3])
        self.Conv5 = conv_block(filters[3], filters[4])

        self.Up5 = up_conv(filters[4], filters[3])
        self.Up_conv5 = conv_block(filters[4], filters[3])

        self.Up4 = up_conv(filters[3], filters[2])
        self.Up_conv4 = conv_block(filters[3], filters[2])

        self.Up3 = up_conv_with_DiffusionUnit(filters[2], filters[1], same_g = same_g, iter_nums = iter_nums)
        self.Up_conv3 = conv_block(filters[2], filters[1])

        self.Up2 = up_conv(filters[1], filters[0])
        self.Up_conv2 = conv_block(filters[1], filters[0])

        self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)


    def forward(self, x):

        e1 = self.Conv1(x)

        e2 = self.Maxpool1(e1)
        e2 = self.Conv2(e2)

        e3 = self.Maxpool2(e2)
        e3 = self.Conv3(e3)

        e4 = self.Maxpool3(e3)
        e4 = self.Conv4(e4)

        e5 = self.Maxpool4(e4)
        e5 = self.Conv5(e5)

        # print("e5 shape:", e5.shape)

        d5 = self.Up5(e5)
        d5 = torch.cat((e4, d5), dim=1)

        d5 = self.Up_conv5(d5)

        d4 = self.Up4(d5)
        d4 = torch.cat((e3, d4), dim=1)
        d4 = self.Up_conv4(d4)

        d3 = self.Up3(d4)
        d3 = torch.cat((e2, d3), dim=1)
        d3 = self.Up_conv3(d3)

        d2 = self.Up2(d3)
        d2 = torch.cat((e1, d2), dim=1)
        d2 = self.Up_conv2(d2)
        out = self.Conv(d2)


        return torch.sigmoid(out)
    


class UNetWithTraditionDiffusion5(nn.Module):
    """
    UNet - Basic Implementation
    Paper : https://arxiv.org/abs/1505.04597
    """
    def __init__(self, in_ch=3, out_ch=1, same_g = True, iter_nums = 2):
        super(UNetWithTraditionDiffusion5, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]
        # print("filters: ", filters)
        
        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.Conv1 = conv_block(in_ch, filters[0])
        self.Conv2 = conv_block(filters[0], filters[1])
        self.Conv3 = conv_block(filters[1], filters[2])
        self.Conv4 = conv_block(filters[2], filters[3])
        self.Conv5 = conv_block(filters[3], filters[4])

        self.Up5 = up_conv(filters[4], filters[3])
        self.Up_conv5 = conv_block(filters[4], filters[3])

        self.Up4 = up_conv(filters[3], filters[2])
        self.Up_conv4 = conv_block(filters[3], filters[2])

        self.Up3 = up_conv(filters[2], filters[1])
        self.Up_conv3 = conv_block(filters[2], filters[1])

        self.Up2 = up_conv_with_DiffusionUnit(filters[1], filters[0], same_g = same_g, iter_nums = iter_nums)
        self.Up_conv2 = conv_block(filters[1], filters[0])

        self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)


    def forward(self, x):

        e1 = self.Conv1(x)

        e2 = self.Maxpool1(e1)
        e2 = self.Conv2(e2)

        e3 = self.Maxpool2(e2)
        e3 = self.Conv3(e3)

        e4 = self.Maxpool3(e3)
        e4 = self.Conv4(e4)

        e5 = self.Maxpool4(e4)
        e5 = self.Conv5(e5)

        # print("e5 shape:", e5.shape)

        d5 = self.Up5(e5)
        d5 = torch.cat((e4, d5), dim=1)

        d5 = self.Up_conv5(d5)

        d4 = self.Up4(d5)
        d4 = torch.cat((e3, d4), dim=1)
        d4 = self.Up_conv4(d4)

        d3 = self.Up3(d4)
        d3 = torch.cat((e2, d3), dim=1)
        d3 = self.Up_conv3(d3)

        d2 = self.Up2(d3)
        d2 = torch.cat((e1, d2), dim=1)
        d2 = self.Up_conv2(d2)
        out = self.Conv(d2)


        return torch.sigmoid(out)
~~~



### 2.3 Att-Unet + 边缘扩散单元的代码(依次是从底往上的四个解码器位置分别添加该单元)

~~~python
   if model_name == "att_unet_with_diffusion2":
        model = Att_UNet_With_Diffusion2(img_ch=3, output_ch=1, iter_nums = 2, same_g = False)
        return model
    
    if model_name == "Att_UNet_With_Diffusion3":
        model = Att_UNet_With_Diffusion3(img_ch=3, output_ch=1, iter_nums = 2, same_g = False)
        return model

    if model_name == "Att_UNet_With_Diffusion4":
        model = Att_UNet_With_Diffusion4(img_ch=3, output_ch=1, iter_nums = 2, same_g = False)
        return model

    if model_name == "Att_UNet_With_Diffusion5":
        model = Att_UNet_With_Diffusion5(img_ch=3, output_ch=1, iter_nums = 2, same_g = False)
        return model
~~~

~~~python
class Att_UNet_With_Diffusion2(nn.Module):
    """
    Attention Unet implementation
    Paper: https://arxiv.org/abs/1804.03999
    """
    def __init__(self, img_ch=3, output_ch=1, iter_nums = 1, same_g = True):
        super(Att_UNet_With_Diffusion2, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]

        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.Conv1 = conv_block(img_ch, filters[0])
        self.Conv2 = conv_block(filters[0], filters[1])
        self.Conv3 = conv_block(filters[1], filters[2])
        self.Conv4 = conv_block(filters[2], filters[3])
        self.Conv5 = conv_block(filters[3], filters[4])

        self.Up5 = up_conv_with_DiffusionUnit(filters[4], filters[3], same_g = same_g, iter_nums = iter_nums)
        self.Att5 = Attention_block(F_g=filters[3], F_l=filters[3], F_int=filters[2])
        self.Up_conv5 = conv_block(filters[4], filters[3])

        self.Up4 = up_conv(filters[3], filters[2])
        self.Att4 = Attention_block(F_g=filters[2], F_l=filters[2], F_int=filters[1])
        self.Up_conv4 = conv_block(filters[3], filters[2])

        self.Up3 = up_conv(filters[2], filters[1])
        self.Att3 = Attention_block(F_g=filters[1], F_l=filters[1], F_int=filters[0])
        self.Up_conv3 = conv_block(filters[2], filters[1])

        self.Up2 = up_conv(filters[1], filters[0])
        self.Att2 = Attention_block(F_g=filters[0], F_l=filters[0], F_int=32)
        self.Up_conv2 = conv_block(filters[1], filters[0])

        self.Conv = nn.Conv2d(filters[0], output_ch, kernel_size=1, stride=1, padding=0)

        #self.active = torch.nn.Sigmoid()


    def forward(self, x):

        e1 = self.Conv1(x)

        e2 = self.Maxpool1(e1)
        e2 = self.Conv2(e2)

        e3 = self.Maxpool2(e2)
        e3 = self.Conv3(e3)

        e4 = self.Maxpool3(e3)
        e4 = self.Conv4(e4)

        e5 = self.Maxpool4(e4)
        e5 = self.Conv5(e5)

        #print(x5.shape)
        d5 = self.Up5(e5)
        #print(d5.shape)
        x4 = self.Att5(g=d5, x=e4)
        d5 = torch.cat((x4, d5), dim=1)
        d5 = self.Up_conv5(d5)

        d4 = self.Up4(d5)
        x3 = self.Att4(g=d4, x=e3)
        d4 = torch.cat((x3, d4), dim=1)
        d4 = self.Up_conv4(d4)

        d3 = self.Up3(d4)
        x2 = self.Att3(g=d3, x=e2)
        d3 = torch.cat((x2, d3), dim=1)
        d3 = self.Up_conv3(d3)

        d2 = self.Up2(d3)
        x1 = self.Att2(g=d2, x=e1)
        d2 = torch.cat((x1, d2), dim=1)
        d2 = self.Up_conv2(d2)

        out = self.Conv(d2)

      #  out = self.active(out)

        return torch.sigmoid(out)

    

class Att_UNet_With_Diffusion3(nn.Module):
    """
    Attention Unet implementation
    Paper: https://arxiv.org/abs/1804.03999
    """
    def __init__(self, img_ch=3, output_ch=1, iter_nums = 1, same_g = True):
        super(Att_UNet_With_Diffusion3, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]

        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.Conv1 = conv_block(img_ch, filters[0])
        self.Conv2 = conv_block(filters[0], filters[1])
        self.Conv3 = conv_block(filters[1], filters[2])
        self.Conv4 = conv_block(filters[2], filters[3])
        self.Conv5 = conv_block(filters[3], filters[4])

        self.Up5 = up_conv(filters[4], filters[3])
        self.Att5 = Attention_block(F_g=filters[3], F_l=filters[3], F_int=filters[2])
        self.Up_conv5 = conv_block(filters[4], filters[3])

        self.Up4 = up_conv_with_DiffusionUnit(filters[3], filters[2], same_g = same_g, iter_nums = iter_nums)
        self.Att4 = Attention_block(F_g=filters[2], F_l=filters[2], F_int=filters[1])
        self.Up_conv4 = conv_block(filters[3], filters[2])

        self.Up3 = up_conv(filters[2], filters[1])
        self.Att3 = Attention_block(F_g=filters[1], F_l=filters[1], F_int=filters[0])
        self.Up_conv3 = conv_block(filters[2], filters[1])

        self.Up2 = up_conv(filters[1], filters[0])
        self.Att2 = Attention_block(F_g=filters[0], F_l=filters[0], F_int=32)
        self.Up_conv2 = conv_block(filters[1], filters[0])

        self.Conv = nn.Conv2d(filters[0], output_ch, kernel_size=1, stride=1, padding=0)

        #self.active = torch.nn.Sigmoid()


    def forward(self, x):

        e1 = self.Conv1(x)

        e2 = self.Maxpool1(e1)
        e2 = self.Conv2(e2)

        e3 = self.Maxpool2(e2)
        e3 = self.Conv3(e3)

        e4 = self.Maxpool3(e3)
        e4 = self.Conv4(e4)

        e5 = self.Maxpool4(e4)
        e5 = self.Conv5(e5)

        #print(x5.shape)
        d5 = self.Up5(e5)
        #print(d5.shape)
        x4 = self.Att5(g=d5, x=e4)
        d5 = torch.cat((x4, d5), dim=1)
        d5 = self.Up_conv5(d5)

        d4 = self.Up4(d5)
        x3 = self.Att4(g=d4, x=e3)
        d4 = torch.cat((x3, d4), dim=1)
        d4 = self.Up_conv4(d4)

        d3 = self.Up3(d4)
        x2 = self.Att3(g=d3, x=e2)
        d3 = torch.cat((x2, d3), dim=1)
        d3 = self.Up_conv3(d3)

        d2 = self.Up2(d3)
        x1 = self.Att2(g=d2, x=e1)
        d2 = torch.cat((x1, d2), dim=1)
        d2 = self.Up_conv2(d2)

        out = self.Conv(d2)

      #  out = self.active(out)

        return torch.sigmoid(out)
    

class Att_UNet_With_Diffusion4(nn.Module):
    """
    Attention Unet implementation
    Paper: https://arxiv.org/abs/1804.03999
    """
    def __init__(self, img_ch=3, output_ch=1, iter_nums = 1, same_g = True):
        super(Att_UNet_With_Diffusion4, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]

        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.Conv1 = conv_block(img_ch, filters[0])
        self.Conv2 = conv_block(filters[0], filters[1])
        self.Conv3 = conv_block(filters[1], filters[2])
        self.Conv4 = conv_block(filters[2], filters[3])
        self.Conv5 = conv_block(filters[3], filters[4])

        self.Up5 = up_conv(filters[4], filters[3])
        self.Att5 = Attention_block(F_g=filters[3], F_l=filters[3], F_int=filters[2])
        self.Up_conv5 = conv_block(filters[4], filters[3])

        self.Up4 = up_conv(filters[3], filters[2])
        self.Att4 = Attention_block(F_g=filters[2], F_l=filters[2], F_int=filters[1])
        self.Up_conv4 = conv_block(filters[3], filters[2])

        self.Up3 = up_conv_with_DiffusionUnit(filters[2], filters[1], same_g = same_g, iter_nums = iter_nums)
        self.Att3 = Attention_block(F_g=filters[1], F_l=filters[1], F_int=filters[0])
        self.Up_conv3 = conv_block(filters[2], filters[1])

        self.Up2 = up_conv(filters[1], filters[0])
        self.Att2 = Attention_block(F_g=filters[0], F_l=filters[0], F_int=32)
        self.Up_conv2 = conv_block(filters[1], filters[0])

        self.Conv = nn.Conv2d(filters[0], output_ch, kernel_size=1, stride=1, padding=0)

        #self.active = torch.nn.Sigmoid()


    def forward(self, x):

        e1 = self.Conv1(x)

        e2 = self.Maxpool1(e1)
        e2 = self.Conv2(e2)

        e3 = self.Maxpool2(e2)
        e3 = self.Conv3(e3)

        e4 = self.Maxpool3(e3)
        e4 = self.Conv4(e4)

        e5 = self.Maxpool4(e4)
        e5 = self.Conv5(e5)

        #print(x5.shape)
        d5 = self.Up5(e5)
        #print(d5.shape)
        x4 = self.Att5(g=d5, x=e4)
        d5 = torch.cat((x4, d5), dim=1)
        d5 = self.Up_conv5(d5)

        d4 = self.Up4(d5)
        x3 = self.Att4(g=d4, x=e3)
        d4 = torch.cat((x3, d4), dim=1)
        d4 = self.Up_conv4(d4)

        d3 = self.Up3(d4)
        x2 = self.Att3(g=d3, x=e2)
        d3 = torch.cat((x2, d3), dim=1)
        d3 = self.Up_conv3(d3)

        d2 = self.Up2(d3)
        x1 = self.Att2(g=d2, x=e1)
        d2 = torch.cat((x1, d2), dim=1)
        d2 = self.Up_conv2(d2)

        out = self.Conv(d2)

      #  out = self.active(out)

        return torch.sigmoid(out)
    



class Att_UNet_With_Diffusion5(nn.Module):
    """
    Attention Unet implementation
    Paper: https://arxiv.org/abs/1804.03999
    """
    def __init__(self, img_ch=3, output_ch=1, iter_nums = 1, same_g = True):
        super(Att_UNet_With_Diffusion5, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]

        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.Conv1 = conv_block(img_ch, filters[0])
        self.Conv2 = conv_block(filters[0], filters[1])
        self.Conv3 = conv_block(filters[1], filters[2])
        self.Conv4 = conv_block(filters[2], filters[3])
        self.Conv5 = conv_block(filters[3], filters[4])

        self.Up5 = up_conv(filters[4], filters[3])
        self.Att5 = Attention_block(F_g=filters[3], F_l=filters[3], F_int=filters[2])
        self.Up_conv5 = conv_block(filters[4], filters[3])

        self.Up4 = up_conv(filters[3], filters[2])
        self.Att4 = Attention_block(F_g=filters[2], F_l=filters[2], F_int=filters[1])
        self.Up_conv4 = conv_block(filters[3], filters[2])

        self.Up3 = up_conv(filters[2], filters[1])
        self.Att3 = Attention_block(F_g=filters[1], F_l=filters[1], F_int=filters[0])
        self.Up_conv3 = conv_block(filters[2], filters[1])

        self.Up2 = up_conv_with_DiffusionUnit(filters[1], filters[0], same_g = same_g, iter_nums = iter_nums)
        self.Att2 = Attention_block(F_g=filters[0], F_l=filters[0], F_int=32)
        self.Up_conv2 = conv_block(filters[1], filters[0])

        self.Conv = nn.Conv2d(filters[0], output_ch, kernel_size=1, stride=1, padding=0)

        #self.active = torch.nn.Sigmoid()


    def forward(self, x):

        e1 = self.Conv1(x)

        e2 = self.Maxpool1(e1)
        e2 = self.Conv2(e2)

        e3 = self.Maxpool2(e2)
        e3 = self.Conv3(e3)

        e4 = self.Maxpool3(e3)
        e4 = self.Conv4(e4)

        e5 = self.Maxpool4(e4)
        e5 = self.Conv5(e5)

        #print(x5.shape)
        d5 = self.Up5(e5)
        #print(d5.shape)
        x4 = self.Att5(g=d5, x=e4)
        d5 = torch.cat((x4, d5), dim=1)
        d5 = self.Up_conv5(d5)

        d4 = self.Up4(d5)
        x3 = self.Att4(g=d4, x=e3)
        d4 = torch.cat((x3, d4), dim=1)
        d4 = self.Up_conv4(d4)

        d3 = self.Up3(d4)
        x2 = self.Att3(g=d3, x=e2)
        d3 = torch.cat((x2, d3), dim=1)
        d3 = self.Up_conv3(d3)

        d2 = self.Up2(d3)
        x1 = self.Att2(g=d2, x=e1)
        d2 = torch.cat((x1, d2), dim=1)
        d2 = self.Up_conv2(d2)

        out = self.Conv(d2)

      #  out = self.active(out)

        return torch.sigmoid(out)
~~~

### 2.4 Unet++ + 边缘扩散单元的代码 (依次是从底往上的四个解码器位置分别添加该单元)

~~~python
 if model_name == 'unet_plus_plus_w_diffusion2':
        model = NestedUNet_With_DiffusionUnet2(in_ch=3, out_ch=1, same_g = False, iter_nums = 2)
        return model
        
 if model_name == "NestedUNet_With_DiffusionUnet3":
        model = NestedUNet_With_DiffusionUnet3(in_ch=3, out_ch=1, same_g = False, iter_nums = 2)
        return model

 if model_name == "NestedUNet_With_DiffusionUnet4":
        model = NestedUNet_With_DiffusionUnet4(in_ch=3, out_ch=1, same_g = False, iter_nums = 2)
        return model
 
if model_name == "NestedUNet_With_DiffusionUnet5":
        model = NestedUNet_With_DiffusionUnet5(in_ch=3, out_ch=1, same_g = False, iter_nums = 2)
        return model
~~~

~~~python
class NestedUNet_With_DiffusionUnet2(nn.Module):
    """
    Implementation of this paper:
    https://arxiv.org/pdf/1807.10165.pdf
    """
    def __init__(self, in_ch=3, out_ch=1, same_g = False, iter_nums = 2):
        super(NestedUNet_With_DiffusionUnet2, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]

        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)

        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0]) 
        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1])
        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2])
        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3])
        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4])

        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0])
        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1])
        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2])
        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3])

        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0])
        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1])
        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2])

        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0])
        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1])

        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0])

        self.up_diffusion_3_1 = up_conv_with_diffusion(in_ch = filters[4], out_ch = filters[4], same_g = same_g, iter_nums = iter_nums)
        self.up_diffusion_2_2 = up_conv(in_ch = filters[3], out_ch = filters[3])
        self.up_diffusion_1_3 = up_conv(in_ch = filters[2], out_ch = filters[2])
        self.up_diffusion_0_4 = up_conv(in_ch = filters[1], out_ch = filters[1])

        self.final = nn.Conv2d(filters[0], out_ch, kernel_size=1)


    def forward(self, x):
        
        x0_0 = self.conv0_0(x)
        x1_0 = self.conv1_0(self.pool(x0_0))
        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up(x1_0)], 1))

        x2_0 = self.conv2_0(self.pool(x1_0))
        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up(x2_0)], 1))
        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up(x1_1)], 1))

        x3_0 = self.conv3_0(self.pool(x2_0))
        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up(x3_0)], 1))
        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up(x2_1)], 1))
        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up(x1_2)], 1))

        x4_0 = self.conv4_0(self.pool(x3_0))
        x4_0_up_diffusion = self.up_diffusion_3_1(x4_0)
        x3_1 = self.conv3_1(torch.cat([x3_0, x4_0_up_diffusion], 1))
        x3_1_up_diffusion = self.up_diffusion_2_2(x3_1)
        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, x3_1_up_diffusion], 1))
        x2_2_up_diffusion = self.up_diffusion_1_3(x2_2)
        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, x2_2_up_diffusion], 1))
        x1_3_up_diffusion = self.up_diffusion_0_4(x1_3)
        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, x1_3_up_diffusion], 1))

        output = self.final(x0_4)
        return torch.sigmoid(output)
    


class NestedUNet_With_DiffusionUnet3(nn.Module):
    """
    Implementation of this paper:
    https://arxiv.org/pdf/1807.10165.pdf
    """
    def __init__(self, in_ch=3, out_ch=1, same_g = False, iter_nums = 2):
        super(NestedUNet_With_DiffusionUnet3, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]

        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)

        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0]) 
        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1])
        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2])
        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3])
        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4])

        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0])
        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1])
        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2])
        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3])

        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0])
        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1])
        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2])

        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0])
        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1])

        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0])

        self.up_diffusion_3_1 = up_conv(in_ch = filters[4], out_ch = filters[4])
        self.up_diffusion_2_2 = up_conv_with_diffusion(in_ch = filters[3], out_ch = filters[3], same_g = same_g, iter_nums = iter_nums)
        self.up_diffusion_1_3 = up_conv(in_ch = filters[2], out_ch = filters[2])
        self.up_diffusion_0_4 = up_conv(in_ch = filters[1], out_ch = filters[1])

        self.final = nn.Conv2d(filters[0], out_ch, kernel_size=1)


    def forward(self, x):
        
        x0_0 = self.conv0_0(x)
        x1_0 = self.conv1_0(self.pool(x0_0))
        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up(x1_0)], 1))

        x2_0 = self.conv2_0(self.pool(x1_0))
        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up(x2_0)], 1))
        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up(x1_1)], 1))

        x3_0 = self.conv3_0(self.pool(x2_0))
        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up(x3_0)], 1))
        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up(x2_1)], 1))
        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up(x1_2)], 1))

        x4_0 = self.conv4_0(self.pool(x3_0))
        x4_0_up_diffusion = self.up_diffusion_3_1(x4_0)
        x3_1 = self.conv3_1(torch.cat([x3_0, x4_0_up_diffusion], 1))
        # print("x3_1", x3_1.shape)
        x3_1_up_diffusion = self.up_diffusion_2_2(x3_1)
        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, x3_1_up_diffusion], 1))
        x2_2_up_diffusion = self.up_diffusion_1_3(x2_2)
        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, x2_2_up_diffusion], 1))
        x1_3_up_diffusion = self.up_diffusion_0_4(x1_3)
        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, x1_3_up_diffusion], 1))

        output = self.final(x0_4)
        return torch.sigmoid(output)
    


class NestedUNet_With_DiffusionUnet4(nn.Module):
    """
    Implementation of this paper:
    https://arxiv.org/pdf/1807.10165.pdf
    """
    def __init__(self, in_ch=3, out_ch=1, same_g = False, iter_nums = 2):
        super(NestedUNet_With_DiffusionUnet4, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]

        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)

        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0]) 
        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1])
        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2])
        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3])
        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4])

        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0])
        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1])
        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2])
        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3])

        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0])
        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1])
        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2])

        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0])
        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1])

        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0])

        self.up_diffusion_3_1 = up_conv(in_ch = filters[4], out_ch = filters[4])
        self.up_diffusion_2_2 = up_conv(in_ch = filters[3], out_ch = filters[3])
        self.up_diffusion_1_3 = up_conv_with_diffusion(in_ch = filters[2], out_ch = filters[2], same_g = same_g, iter_nums = iter_nums)
        self.up_diffusion_0_4 = up_conv(in_ch = filters[1], out_ch = filters[1])

        self.final = nn.Conv2d(filters[0], out_ch, kernel_size=1)


    def forward(self, x):
        
        x0_0 = self.conv0_0(x)
        x1_0 = self.conv1_0(self.pool(x0_0))
        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up(x1_0)], 1))

        x2_0 = self.conv2_0(self.pool(x1_0))
        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up(x2_0)], 1))
        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up(x1_1)], 1))

        x3_0 = self.conv3_0(self.pool(x2_0))
        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up(x3_0)], 1))
        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up(x2_1)], 1))
        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up(x1_2)], 1))

        x4_0 = self.conv4_0(self.pool(x3_0))
        x4_0_up_diffusion = self.up_diffusion_3_1(x4_0)
        x3_1 = self.conv3_1(torch.cat([x3_0, x4_0_up_diffusion], 1))
        x3_1_up_diffusion = self.up_diffusion_2_2(x3_1)
        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, x3_1_up_diffusion], 1))
        x2_2_up_diffusion = self.up_diffusion_1_3(x2_2)
        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, x2_2_up_diffusion], 1))
        x1_3_up_diffusion = self.up_diffusion_0_4(x1_3)
        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, x1_3_up_diffusion], 1))

        output = self.final(x0_4)
        return torch.sigmoid(output)
    


class NestedUNet_With_DiffusionUnet5(nn.Module):
    """
    Implementation of this paper:
    https://arxiv.org/pdf/1807.10165.pdf
    """
    def __init__(self, in_ch=3, out_ch=1, same_g = False, iter_nums = 2):
        super(NestedUNet_With_DiffusionUnet5, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]

        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)

        self.conv0_0 = conv_block_nested(in_ch, filters[0], filters[0]) 
        self.conv1_0 = conv_block_nested(filters[0], filters[1], filters[1])
        self.conv2_0 = conv_block_nested(filters[1], filters[2], filters[2])
        self.conv3_0 = conv_block_nested(filters[2], filters[3], filters[3])
        self.conv4_0 = conv_block_nested(filters[3], filters[4], filters[4])

        self.conv0_1 = conv_block_nested(filters[0] + filters[1], filters[0], filters[0])
        self.conv1_1 = conv_block_nested(filters[1] + filters[2], filters[1], filters[1])
        self.conv2_1 = conv_block_nested(filters[2] + filters[3], filters[2], filters[2])
        self.conv3_1 = conv_block_nested(filters[3] + filters[4], filters[3], filters[3])

        self.conv0_2 = conv_block_nested(filters[0]*2 + filters[1], filters[0], filters[0])
        self.conv1_2 = conv_block_nested(filters[1]*2 + filters[2], filters[1], filters[1])
        self.conv2_2 = conv_block_nested(filters[2]*2 + filters[3], filters[2], filters[2])

        self.conv0_3 = conv_block_nested(filters[0]*3 + filters[1], filters[0], filters[0])
        self.conv1_3 = conv_block_nested(filters[1]*3 + filters[2], filters[1], filters[1])

        self.conv0_4 = conv_block_nested(filters[0]*4 + filters[1], filters[0], filters[0])

        self.up_diffusion_3_1 = up_conv(in_ch = filters[4], out_ch = filters[4])
        self.up_diffusion_2_2 = up_conv(in_ch = filters[3], out_ch = filters[3])
        self.up_diffusion_1_3 = up_conv(in_ch = filters[2], out_ch = filters[2])
        self.up_diffusion_0_4 = up_conv_with_diffusion(in_ch = filters[1], out_ch = filters[1], same_g = same_g, iter_nums = iter_nums)

        self.final = nn.Conv2d(filters[0], out_ch, kernel_size=1)


    def forward(self, x):
        
        x0_0 = self.conv0_0(x)
        x1_0 = self.conv1_0(self.pool(x0_0))
        x0_1 = self.conv0_1(torch.cat([x0_0, self.Up(x1_0)], 1))

        x2_0 = self.conv2_0(self.pool(x1_0))
        x1_1 = self.conv1_1(torch.cat([x1_0, self.Up(x2_0)], 1))
        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.Up(x1_1)], 1))

        x3_0 = self.conv3_0(self.pool(x2_0))
        x2_1 = self.conv2_1(torch.cat([x2_0, self.Up(x3_0)], 1))
        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.Up(x2_1)], 1))
        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.Up(x1_2)], 1))

        x4_0 = self.conv4_0(self.pool(x3_0))
        x4_0_up_diffusion = self.up_diffusion_3_1(x4_0)
        x3_1 = self.conv3_1(torch.cat([x3_0, x4_0_up_diffusion], 1))
        x3_1_up_diffusion = self.up_diffusion_2_2(x3_1)
        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, x3_1_up_diffusion], 1))
        x2_2_up_diffusion = self.up_diffusion_1_3(x2_2)
        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, x2_2_up_diffusion], 1))
        x1_3_up_diffusion = self.up_diffusion_0_4(x1_3)
        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, x1_3_up_diffusion], 1))

        output = self.final(x0_4)
        return torch.sigmoid(output)
~~~

## 第五章模型代码

采用“采用膨胀操作和腐蚀操作的平均”方法来计算不确定性度（实际上该方法是在forward里进行的，而下面的这段代码是“不确定性计算方法”，我们并不需要，只是之前模型里忘记移除了，所以需要补上这段代码以确保运行）

~~~python
class UncertaintyMaskModule(nn.Module):
    
    def __init__(self, threshold):
        super(UncertaintyMaskModule, self).__init__()
        self.threshold = threshold

    def forward(self, x):
        # x.shape = (N, 1, H, W)
        # 对每个元素值进行计算相似性值
        # std应该针对的是每个图片对应的预测概率图，而不是一组图片对应的所有概率预测图
        # 所以必须对每张图片分开进行计算，然后再拼接回去就行
        uncertainty_map = None
        for img_th in range(x.shape[0]):
            img = x[img_th] # (1, H, W)
            std = torch.std(img) 
            img = torch.exp(-torch.square(img - 0.5) / (2 * std * std))
            if img_th == 0:
                uncertainty_map = img
            else:
                uncertainty_map = torch.cat((uncertainty_map, img), 0)
        
        uncertainty_map = uncertainty_map.unsqueeze(1)

        # print("uncertainty_map shape: ", uncertainty_map.shape)
        # print("uncertainty_map max:", torch.max(uncertainty_map))
        # print("uncertainty_map min:", torch.min(uncertainty_map))
        
        # 然后对相似性值进行过滤
        thresholded_uncertainty_map = uncertainty_map.clone()
        # print("thresholded_uncertainty_map:", thresholded_uncertainty_map)
        # print("小于等于", thresholded_uncertainty_map[thresholded_uncertainty_map <= self.threshold])

        thresholded_uncertainty_mask = torch.where(thresholded_uncertainty_map > self.threshold, 1, 0)

        # print("thresholded_uncertainty_map 2:", thresholded_uncertainty_map[thresholded_uncertainty_map == 1])

        # print("thresholded_uncertainty_map shape:", thresholded_uncertainty_map.shape)
        
        # 这里阈值化后的很明显是mask，阈值化之前的只是不确定程度
        return uncertainty_map, thresholded_uncertainty_mask
~~~



精细特征获取模块的代码：

~~~python
# ECA（Efficient Channel Attention）
class eca(nn.Module):
    def __init__(self, k_size=3):
        super(eca, self).__init__()
        self.avg_pool = nn.AdaptiveMaxPool2d(1)
        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, stride=1, padding=(k_size - 1) // 2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x): # torch.Size([1, 32, 128, 128])
        y = self.avg_pool(x) # torch.Size([1, 32, 1, 1])
        z = y.squeeze(-1).transpose(-1, -2) # torch.Size([1, 1, 32])
        y = self.conv(z).transpose(-1, -2).unsqueeze(-1)  # torch.Size([1, 32, 1, 1])
        y = self.sigmoid(y)
        return x * y.expand_as(x)


class MultiScaleFineGrainedFeatureFusion(nn.Module): #32 64 64 32
    def __init__(self, in_ch1, in_ch2, in_ch3, out_ch):
        super(MultiScaleFineGrainedFeatureFusion, self).__init__()
        self.out_ch = out_ch
        self.up2 = up_(in_ch2, out_ch, scale_factor=2)
        self.up3 = up_(in_ch3, out_ch, scale_factor=4)
        self.fusion = nn.Conv2d(out_ch * 3, out_ch, 1)
        self.eca = eca()
        self.gamma = nn.Parameter(torch.zeros(1))

    
    # x1.shape:torch.Size([1, 32, 128, 128]) 
    # x2.shape: torch.Size([1, 64, 64, 64])
    # x3.shape: torch.Size([1, 64, 32, 32])
    def forward(self, x1, x2, x3):
        x2 = self.up2(x2) # torch.Size([1, 32, 128, 128])
        x3 = self.up3(x3) # torch.Size([1, 32, 128, 128])
        x4 = torch.cat([x1, x2, x3], dim=1)   # torch.Size([1, 96, 128, 128])
        x4 = self.fusion(x4)  # torch.Size([1, 32, 128, 128])
        out = self.eca(x4) 
        out = self.gamma * out + x4
        return out
~~~



总的模型结构：

~~~python
class UNet_W_MSFGFF2_3(nn.Module):
    """
    UNet - Basic Implementation
    Paper : https://arxiv.org/abs/1505.04597
    """
    def __init__(self, in_ch=3, out_ch=1):
        super(UNet_W_MSFGFF2_3, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]
        # print("filters: ", filters)
        
        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.Conv1 = conv_block(in_ch, filters[0])
        self.Conv2 = conv_block(filters[0], filters[1])
        self.Conv3 = conv_block(filters[1], filters[2])
        self.Conv4 = conv_block(filters[2], filters[3])
        self.Conv5 = conv_block(filters[3], filters[4])

        self.Up5 = up_conv(filters[4], filters[3])
        self.Up_conv5 = conv_block(filters[4], filters[3])

        self.Up4 = up_conv(filters[3], filters[2])
        self.Up_conv4 = conv_block(filters[3], filters[2])

        self.Up3 = up_conv(filters[2], filters[1])
        self.Up_conv3 = conv_block(filters[2], filters[1])

        self.Up2 = up_conv(filters[1], filters[0])
        self.Up_conv2 = conv_block(filters[1], filters[0])

        self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)
        self.uncertainty_mask = UncertaintyMaskModule(0.5)
        # self.boundary_maxpool = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)
        # self.boundary_maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
        # self.boundary_maxpool = nn.MaxPool2d(kernel_size=7, stride=1, padding=3)
        self.boundary_maxpool = nn.MaxPool2d(kernel_size=9, stride=1, padding=4)


        self.msfgff = MultiScaleFineGrainedFeatureFusion(in_ch1=64, in_ch2=128, in_ch3=256, out_ch=64)
        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))
        self.final_fc = nn.Linear(64, 1, bias=True)


    def forward(self, x):

        e1 = self.Conv1(x)

        e2 = self.Maxpool1(e1)
        e2 = self.Conv2(e2)

        e3 = self.Maxpool2(e2)
        e3 = self.Conv3(e3)

        e4 = self.Maxpool3(e3)
        e4 = self.Conv4(e4)

        e5 = self.Maxpool4(e4)
        e5 = self.Conv5(e5)

        # print("e5 shape:", e5.shape)

        d5 = self.Up5(e5)
        d5 = torch.cat((e4, d5), dim=1)

        d5 = self.Up_conv5(d5)

        d4 = self.Up4(d5)
        d4 = torch.cat((e3, d4), dim=1)
        d4 = self.Up_conv4(d4)

        d3 = self.Up3(d4)
        d3 = torch.cat((e2, d3), dim=1)
        d3 = self.Up_conv3(d3)

        d2 = self.Up2(d3)
        d2 = torch.cat((e1, d2), dim=1)
        d2 = self.Up_conv2(d2)


        out = self.Conv(d2)

        uncertainty_map, thresholded_uncertainty_mask = self.uncertainty_mask(out)
        out_dilation = self.boundary_maxpool(out)
        out_erosion  = -self.boundary_maxpool(-out)
        out_tenary_atttention_map = (out_erosion + out_dilation) / 2
        
        background_sigmoid_value_threshold = 0.5
        core_foreground_sigmoid_value_threshold = 0.8
        boundary_mask = torch.where(torch.logical_and(out_tenary_atttention_map >= background_sigmoid_value_threshold, out_tenary_atttention_map <= core_foreground_sigmoid_value_threshold), 1, 0)


        merged_uncertainty_mask = boundary_mask.to(torch.int)
        background_mask = torch.where(merged_uncertainty_mask == 0, 1, 0)
        

        merged_fined_features = self.msfgff(d2, d3, d4)
        merged_fined_features_pooled = self.avgpool(merged_fined_features).squeeze(-1).squeeze(-1)
        classification_result = self.final_fc(merged_fined_features_pooled)
        classification_result = torch.sigmoid(classification_result) # 预测为1，也就是预测肿块的概率


        refined_d2 = ((merged_fined_features + d2) / 2) * merged_uncertainty_mask + background_mask * d2
        refined_out = self.Conv(refined_d2)
        refined_uncertainty_map, refined_thresholded_uncertainty_mask = self.uncertainty_mask(refined_out)

        return torch.sigmoid(refined_out), torch.sigmoid(out), classification_result, uncertainty_map, thresholded_uncertainty_mask, boundary_mask, merged_uncertainty_mask, refined_uncertainty_map

~~~

torch.sigmoid(refined_out), torch.sigmoid(out), classification_result, uncertainty_map, thresholded_uncertainty_mask, boundary_mask, merged_uncertainty_mask, refined_uncertainty_map分别是精细分割预测、粗糙分割预测（U-net直接输出的原始分割预测结果）、乳腺癌良恶性分类结果、不确定性热力图、阈值化后得到的不确定性掩膜、边界掩膜、合并后得到的不确定性掩膜、特征细化后的不确定性热力图



模型训练代码：

~~~python
def make_training_w_classification_task2(config_path, model_name, train_imgs_dir, train_labels_dir, train_edges_dir,
                val_imgs_dir, val_labels_dir, val_edges_dir, multi_channels=True, weighted_loss=False, model_name_extra=''):

    seed = 10
    setup_seed(seed)

    #########################################
    # 获得数据
    #########################################


    training_data = ImagesDatasetWithEdgeNoDeformation2(train_imgs_dir, train_labels_dir, train_edges_dir)
    validating_data = ImagesDatasetWithEdgeNoDeformation2(val_imgs_dir, val_labels_dir, val_edges_dir)
    # 加载配置参数
    parm_settings = get_params(config_path)
    print("config:", parm_settings)
    print(parm_settings.TRAIN.BATCH_SIZE)


    # 构建数据加载器
    train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=parm_settings.TRAIN.BATCH_SIZE, 
                            num_workers=parm_settings.TRAIN.NUM_WORKERS, pin_memory=parm_settings.TRAIN.PIN_MEMORY)
    val_dataloader = torch.utils.data.DataLoader(validating_data, batch_size=parm_settings.TEST.BATCH_SIZE, 
                             num_workers=parm_settings.TEST.NUM_WORKERS, pin_memory=parm_settings.TEST.PIN_MEMORY)
    
    #######################################
    # 创建模型
    #######################################

    model = get_model(model_name, original_latent_dim=500, transformed_dim=1024)

    device = get_device(using_gpu=True)
    model.to(device)

    if model_name == 'deep_latent_unet':
        model.deep_latent.to(device)
    
    start_epoch = -1
    
    if len(parm_settings.TRAIN.MODEL_PATH):
        model.load_state_dict(torch.load(parm_settings.TRAIN.MODEL_PATH))

        # # 获取检查点文件的epoch数目
        # start_epoch = int(parm_settings.TRAIN.MODEL_PATH.split('.')[0].split('_')[-3])
        start_epoch = 0
        print("start epoch is:", start_epoch)
        

    # print("-" * 30)
    # torchsummary.summary(model, input_size=(3, 128, 128))
    # print("-" * 30)

    ######################################
    # 设置好学习率、优化器
    ######################################
    # initial_lr = 0.001
    # opt = torch.optim.SGD(model.parameters(), lr = initial_lr)

    # opt = torch.optim.Adam(model.parameters(), lr=initial_lr) # try SGD
    # opt = torch.optim.SGD(model.parameters(), lr = initial_lr, momentum=0.99)

    initial_lr = 0.0006
    opt = torch.optim.Adagrad(model.parameters(), lr=initial_lr)

    # MAX_STEP = int(1e10)
    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, MAX_STEP, eta_min=1e-5)

    ######################################
    # 创建模型的保存目录
    ######################################
    models_saved_dir = PROJECT_RESULT_DIR + '/results'
    create_folder(models_saved_dir)


    # 生成当前时间的唯一时间戳
    timestamp = int(time.time())
    # 格式化时间戳为指定格式
    formatted_time = time.strftime("%Y%m%d_%H:%M:%S", time.localtime(timestamp))
    model_name = model_name + formatted_time

    if model_name_extra:
        cur_model_subfolder_name = model_name + "_" + model_name_extra + "_" + str(parm_settings.TRAIN.NUM_EPOCHS) + "_" + str(parm_settings.TRAIN.BATCH_SIZE)
    else:
        cur_model_subfolder_name = model_name + "_" + str(parm_settings.TRAIN.NUM_EPOCHS) + "_" + str(parm_settings.TRAIN.BATCH_SIZE)

    cur_model_subfolder_path = os.path.join(models_saved_dir, cur_model_subfolder_name)


    if start_epoch != -1:
        is_clear_exists = False
    else:
        is_clear_exists = True
    create_folder(cur_model_subfolder_path, is_clear = is_clear_exists)
    
    trained_models_path = os.path.join(cur_model_subfolder_path, 'trained_models')
    preds_path = os.path.join(cur_model_subfolder_path, 'preds')
    intermediate_resluts_path = os.path.join(cur_model_subfolder_path, 'intermediate_results')
    create_folder(trained_models_path, is_clear = is_clear_exists)
    create_folder(preds_path, is_clear = is_clear_exists)
    create_folder(intermediate_resluts_path, is_clear = is_clear_exists)

    ##################################################################################
    # 进行模型的训练与验证
    ##################################################################################

    best_epoch = 0
    best_ckpt_path = ''

    val_loss_min = inf
    val_score_min = -inf

    since = time.time()

    for i in range(start_epoch+1, parm_settings.TRAIN.NUM_EPOCHS):

        #############################################
        # 设置初始参数
        #############################################
        train_loss = 0.0
        val_loss = 0.0
        train_score = 0.0
        val_score = 0.0
        train_len = 0
        val_len = 0

        train_y_pred_numpy = None
        train_y_label_numpy = None
        val_y_pred_numpy = None
        val_y_label_numpy = None

        epoch_since = time.time()

        # scheduler.step(i)
        # lr = scheduler.get_lr()

        ######################################################
        # 模型训练
        ######################################################
        
        model.train()

        for j, (classification_label, x, x_path, y, y_path, z, z_path, slic, slic_path) in enumerate(train_dataloader):

            # print("y_path:", y_path)

            x = x.to(device)
            y = y.to(device)
            z = z.to(device)

            classification_label = classification_label.to(device)
            # print("slic type:", type(slic))
            # print("slic:", slic)

            if multi_channels:
                slic = slic.to(device)
            
            if j == 0:
                fig_saved_path = os.path.join(intermediate_resluts_path, str(j) + "_initial.png")
                plot_input_images(x, y, fig_saved_path)

            opt.zero_grad()

            # print(x.shape)

            if multi_channels:
                model_input = torch.cat([x, slic], dim=1)
            else:
                model_input = x

            y_pred, y_pred_coarse, y_classification, uncertainty_map, thresholded_uncertainty_mask, boundary_mask, merged_uncertainty_mask, refined_uncertainty_map = model(model_input)

            if not weighted_loss:
                train_dice_loss, score = calc_dice_loss_0(y_pred, y)
                train_dice_loss2, score2 = calc_dice_loss_0(y_pred_coarse, y)
            else:
                # print("using weighted_loss")
                # print("y_pred shape:", y_pred.shape)
                # print("y shape:", y.shape)
                train_dice_loss, score = calculate_unet_weighted_loss(y_pred, y)
                train_dice_loss2, score2 = calculate_unet_weighted_loss(y_pred_coarse, y)

            train_dice_loss += train_dice_loss2
            score += score2

            classification_bce_loss = binary_classification_bce_loss(y_classification, classification_label)

            train_dice_loss += classification_bce_loss

            if j == 0:
                train_y_pred_numpy = y_pred.cpu().detach().numpy()
                train_y_label_numpy = y.cpu().detach().numpy()
            else:
                train_y_pred_numpy = np.concatenate((train_y_pred_numpy, y_pred.cpu().detach().numpy()), axis=0)
                train_y_label_numpy = np.concatenate((train_y_label_numpy, y.cpu().detach().numpy()), axis=0)

            train_dice_loss.backward()

            train_loss += train_dice_loss.item()
            train_score += score.item()

            # cur_train_scores = scores(train_y_label_numpy, train_y_pred_numpy, 2)
            # print("cur_train_scores:")
            # print_dict(cur_train_scores)

            opt.step()

            train_len += x.size()[0]

        ##############################################
        # 模型验证
        ##############################################
        model.eval()
        torch.no_grad()

        # 保存本轮迭代的验证结果
        # preds_epoch_dir = os.path.join(preds_path, 'epoch_' + str(i))
        # create_folder(preds_epoch_dir)

        for t, (classification_label, x, x_path, y, y_path, z, z_path, slic, slic_path) in enumerate(val_dataloader):

            x, y = x.to(device), y.to(device)
            classification_label = classification_label.to(device)
            z = z.to(device)
            if multi_channels:
                slic = slic.to(device)

            x_img_name = os.path.basename(x_path[0]).split(".")[0]

            if multi_channels:
                model_input = torch.cat([x, slic], dim=1)
            else:
                model_input = x
            y_pred, y_pred_coarse, y_classification, uncertainty_map, thresholded_uncertainty_mask, boundary_mask, merged_uncertainty_mask, refined_uncertainty_map = model(model_input)

            if not weighted_loss:
                val_dice_loss, score = calc_dice_loss_0(y_pred, y)
                val_dice_loss2, score2 = calc_dice_loss_0(y_pred_coarse, y)
            else:
                val_dice_loss, score = calculate_unet_weighted_loss(y_pred, y)
                val_dice_loss2, score2 = calculate_unet_weighted_loss(y_pred_coarse, y)

            val_dice_loss += val_dice_loss2
            score += score2

            classification_bce_loss = binary_classification_bce_loss(y_classification, classification_label)
            val_dice_loss += classification_bce_loss

            val_loss += val_dice_loss.item() 
            val_score += score.item()
            
            val_len += x.size()[0]

            if t == 0:
                val_y_pred_numpy = y_pred.cpu().detach().numpy()
                val_y_label_numpy = y.cpu().detach().numpy()
            else:
                val_y_pred_numpy = np.concatenate((val_y_pred_numpy, y_pred.cpu().detach().numpy()), axis=0)
                val_y_label_numpy = np.concatenate((val_y_label_numpy, y.cpu().detach().numpy()), axis=0)

            # 保存预测的热力图
            # y_pred_heatmap = y_pred.cpu().detach().numpy()
            # heatmap_saved_path = os.path.join(preds_epoch_dir, x_img_name + "_heatmap.png")
            # y_pred_heatmap_normalized = (y_pred_heatmap / np.max(y_pred_heatmap)) * 255
            # y_pred_heatmap_normalized = y_pred_heatmap_normalized.astype(np.uint8)
            # heatmap_normalized_saved_path = os.path.join(preds_epoch_dir, x_img_name + "_heatmap_normalized.png")
            # plt.imsave(heatmap_saved_path, y_pred_heatmap[0][0])
            # cv2.imwrite(heatmap_normalized_saved_path, y_pred_heatmap_normalized[0][0])

            # 保存预测的分割结果
            # y_pred_seg  = torch.sigmoid(y_pred)
            # y_pred_seg = y_pred
            # y_pred_seg = threshold_predictions_p(y_pred_seg)
            # y_pred_seg = y_pred_seg.cpu().detach().numpy()
            # seg_saved_path = os.path.join(preds_epoch_dir, x_img_name + "_seg.png")
            # cv2.imwrite(seg_saved_path, y_pred_seg[0][0])
     
    
        ##############################################
        # 打印当前迭代次数的结果，并据此保存检查点文件
        ##############################################
        train_loss /= train_len
        train_score /= train_len
        val_loss /= val_len
        val_score /= val_len

        train_y_pred_numpy[train_y_pred_numpy > 0.5] = 1
        val_y_pred_numpy[val_y_pred_numpy > 0.5] = 1
        train_y_pred_numpy[train_y_pred_numpy <= 0.5] = 0
        val_y_pred_numpy[val_y_pred_numpy <= 0.5] = 0

        train_y_pred_numpy = train_y_pred_numpy.astype(np.uint8)
        val_y_pred_numpy = val_y_pred_numpy.astype(np.uint8)
        train_y_label_numpy = train_y_label_numpy.astype(np.uint8)
        val_y_label_numpy = val_y_label_numpy.astype(np.uint8)

        train_scores = scores(train_y_label_numpy, train_y_pred_numpy, 2)
        val_scores = scores(val_y_label_numpy, val_y_pred_numpy, 2)


        print("-----------------S: Epoch {:}/{:}--------------------".format(i, parm_settings.TRAIN.NUM_EPOCHS))
        # print("TrainingLoss:{:.6f} TrainScore:{:.6f}".format(train_loss, train_score))
        print("TrainingLoss:{:.6f}".format(train_loss))
        print("Train scores:")
        print_dict(train_scores)

        # print("ValLoss:{:.6f} ValScore:{:.6f}".format(val_loss, val_score))
        print("ValLoss:{:.6f}".format(val_loss))

        print("Val scores:")
        print_dict(val_scores)

        # print("type of val_score: ", type(val_scores))
        # print("type of val_score[whole dice (dsc)]: " , type(val_scores["whole dice   (dsc)"]))

        # if val_loss <= val_loss_min:
        if val_scores["whole dice (dsc)"] >= val_score_min: 
            print('Val Loss decreased ({:.6f} --> {:.6f}).'.format(val_loss_min, val_loss))

            val_loss_min = val_loss
            val_score_min = val_scores["whole dice (dsc)"]

            best_epoch = i
            model_ckpt_name = model_name + '_epoch_' + str(i) + '_batchsize_' + str(parm_settings.TRAIN.BATCH_SIZE) + ".pth"
            model_ckpt_saved_path = os.path.join(trained_models_path, model_ckpt_name)
            best_ckpt_path = model_ckpt_saved_path
            torch.save(model.state_dict(), model_ckpt_saved_path)
        
        epoch_end  = time.time()
        epoch_elaspe = epoch_end - epoch_since
        print('Epoch elapsed: {:.0f}m {:.0f}s'.format(epoch_elaspe // 60, epoch_elaspe % 60))
        print("-----------------E: Epoch {:}/{:}--------------------".format(i, parm_settings.TRAIN.NUM_EPOCHS))
        print('\n')


    time_elapsed = time.time() - since
    print("Duration: {:.0f}m {:.0f}s".format(time_elapsed // 60, time_elapsed % 60))
    print("best_epoch is:", best_epoch)
    print("best checkpoint is:", best_ckpt_path)
    print("\n\n\n\n")
    ######################################################
    # 保存任意中间层的结果
    ######################################################

    return best_ckpt_path
~~~



模型测试代码：

~~~python
def make_testing_w_classification_task2(config_path, model_name, test_imgs_dir, test_labels_dir, test_edges_dir, 
                    best_ckpt_path = '', multi_channels=True, weighted_loss=False):
    #########################################
    # 获得数据
    #########################################


    testing_data = ImagesDatasetWithEdgeNoDeformation2(test_imgs_dir, test_labels_dir, test_edges_dir)


    # 加载配置参数
    parm_settings = get_params(config_path)
    print("config:", parm_settings)
    print(parm_settings.TEST.BATCH_SIZE)

    # 构建数据加载器
    test_dataloader = torch.utils.data.DataLoader(testing_data, batch_size=parm_settings.TEST.BATCH_SIZE, 
                           num_workers=parm_settings.TEST.NUM_WORKERS, pin_memory=parm_settings.TEST.PIN_MEMORY)
    
    #######################################
    # 创建模型、加载模型
    #######################################

    model = get_model(model_name)
    device = get_device(using_gpu=True)
    model.to(device)

    if len(best_ckpt_path):
        model.load_state_dict(torch.load(best_ckpt_path))
    else:
        model.load_state_dict(torch.load(parm_settings.TEST.MODEL_PATH))

    model.eval()

    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    ########################################
    # 在测试集上对模型进行测试
    ########################################

    test_loss = 0.0
    test_len = 0
    test_score = 0.0

    if best_ckpt_path:
        model_saved_path = '/'.join(best_ckpt_path.split("/")[:-2])
    else:
        model_saved_path = '/'.join(parm_settings.TEST.MODEL_PATH.split("/")[:-2])
    test_preds_saved_folder = os.path.join(model_saved_path + '/preds/', 'test')
    create_folder(test_preds_saved_folder)

    test_y_label_numpy = None
    test_y_pred_numpy = None

    for i, (classification_label, x, x_path, y, y_path, z, z_path, slic, slic_path) in enumerate(test_dataloader):

        # print("y_path:", y_path)
        x = x.to(device)
        y = y.to(device)
        z = z.to(device)
        classification_label = classification_label.to(device)

        if multi_channels:
            slic = slic.to(device)

        x_img_name = os.path.basename(x_path[0]).split(".")[0]

        if multi_channels:
            model_input = torch.cat([x, slic], dim=1)
        else:
            model_input = x
        
        y_pred, y_pred_coarse, y_classification, uncertainty_map, thresholded_uncertainty_mask, boundary_mask, merged_uncertainty_mask, refined_uncertainty_map = model(model_input)

        if i == 0:
            test_y_pred_numpy = y_pred.cpu().detach().numpy()
            test_y_label_numpy = y.cpu().detach().numpy()
        else:
            test_y_pred_numpy = np.concatenate((test_y_pred_numpy, y_pred.cpu().detach().numpy()), axis=0)
            test_y_label_numpy = np.concatenate((test_y_label_numpy, y.cpu().detach().numpy()), axis=0)

        if not weighted_loss:
            test_dice_loss, score = calc_dice_loss_0(y_pred, y)
            test_dice_loss2, score2 = calc_dice_loss_0(y_pred_coarse, y)
        else:
            test_dice_loss, score = calculate_unet_weighted_loss(y_pred, y)
            test_dice_loss2, score2 = calculate_unet_weighted_loss(y_pred_coarse, y)

        test_dice_loss += test_dice_loss2
        score += score2

        # edge_loss = edge_mse_loss(y_pred, z)
            
        classification_bce_loss = binary_classification_bce_loss(y_classification, classification_label)

        test_dice_loss += classification_bce_loss

        test_loss += test_dice_loss.item()
        test_score += score.item()

        test_len += x.size()[0]



        # 保存预测的热力图
        y_pred_heatmap = y_pred.cpu().detach().numpy()
        # print("y_pred", y_pred_heatmap)
        heatmap_saved_path = os.path.join(test_preds_saved_folder, x_img_name + "_heatmap.png")
        y_pred_heatmap_normalized = (y_pred_heatmap / np.max(y_pred_heatmap)) * 255
        y_pred_heatmap_normalized = y_pred_heatmap_normalized.astype(np.uint8)
        heatmap_normalized_saved_path = os.path.join(test_preds_saved_folder, x_img_name + "_heatmap_normalized.png")
        plt.imsave(heatmap_saved_path, y_pred_heatmap[0][0])
        cv2.imwrite(heatmap_normalized_saved_path, y_pred_heatmap_normalized[0][0])

        # 保存预测的分割结果
        # y_pred_seg  = torch.sigmoid(y_pred)
        y_pred_seg = y_pred
        y_pred_seg = threshold_predictions_p(y_pred_seg)
        y_pred_seg = y_pred_seg.cpu().detach().numpy()
        seg_saved_path = os.path.join(test_preds_saved_folder, x_img_name + "_seg.png")
        cv2.imwrite(seg_saved_path, y_pred_seg[0][0])


        # 保存初步的uncertainty_mapss
        uncertainty_map_heatmap = uncertainty_map.cpu().detach().numpy()
        uncertainty_map_heatmap_save_path = os.path.join(test_preds_saved_folder, x_img_name + "_uncertainty_map_heatmap.png")
        # uncertainty_map_heatmap_normalized = (uncertainty_map_heatmap / np.max(uncertainty_map_heatmap)) * 255
        # uncertainty_map_heatmap_normalized = uncertainty_map_heatmap.astype(np.uint8)
        # uncertainty_map_heatmap_normalized_saved_path = os.path.join(test_preds_saved_folder, x_img_name + "_uncertainty_map_heatmap_normalized.png")
        plt.imsave(uncertainty_map_heatmap_save_path, uncertainty_map_heatmap[0][0])
        # cv2.imwrite(uncertainty_map_heatmap_normalized_saved_path, uncertainty_map_heatmap_normalized[0][0])


        # 保存thresholded_uncertainty_mask
        thresholded_uncertainty_mask = thresholded_uncertainty_mask.cpu().detach().numpy()
        thresholded_uncertainty_mask[thresholded_uncertainty_mask == 1] = 255
        thresholded_uncertainty_mask_saved_path = os.path.join(test_preds_saved_folder, x_img_name + "_thresholded_uncertainty_mask.png")
        cv2.imwrite(thresholded_uncertainty_mask_saved_path, thresholded_uncertainty_mask[0][0])


        # 保存细化后的uncertainty_map
        uncertainty_map_heatmap = refined_uncertainty_map.cpu().detach().numpy()
        uncertainty_map_heatmap_save_path = os.path.join(test_preds_saved_folder, x_img_name + "_refined_uncertainty_map_heatmap.png")
        # uncertainty_map_heatmap_normalized = (uncertainty_map_heatmap / np.max(uncertainty_map_heatmap)) * 255
        # uncertainty_map_heatmap_normalized = uncertainty_map_heatmap.astype(np.uint8)
        # uncertainty_map_heatmap_normalized_saved_path = os.path.join(test_preds_saved_folder, x_img_name + "_refined_uncertainty_map_heatmap_normalized.png")
        plt.imsave(uncertainty_map_heatmap_save_path, uncertainty_map_heatmap[0][0])
        # cv2.imwrite(uncertainty_map_heatmap_normalized_saved_path, uncertainty_map_heatmap_normalized[0][0])
        


        # 保存boundary_mask
        boundary_mask = boundary_mask.cpu().detach().numpy()
        boundary_mask[boundary_mask == 1] = 255
        boundary_mask_saved_path = os.path.join(test_preds_saved_folder, x_img_name + "_boundary_mask.png")
        cv2.imwrite(boundary_mask_saved_path, boundary_mask[0][0])


        # 保存merged_uncertainty_mask
        merged_uncertainty_mask = merged_uncertainty_mask.cpu().detach().numpy()
        merged_uncertainty_mask[merged_uncertainty_mask == 1] = 255
        merged_uncertainty_mask_saved_path = os.path.join(test_preds_saved_folder, x_img_name + "_merged_uncertainty_mask.png")
        cv2.imwrite(merged_uncertainty_mask_saved_path, merged_uncertainty_mask[0][0])


        # print("x_path len: " + str(len(x_path)))
        for ith in range(len(y_path)):
            x_img = cv2.imread(x_path[ith])
            x_img_resize = cv2.resize(x_img,(128,128))
            x_img_name = x_path[ith].split("/")[-1]
            cv2.imwrite(os.path.join(test_preds_saved_folder, x_img_name), x_img_resize)

            y_label = cv2.imread(y_path[ith])
            y_label_resize = cv2.resize(y_label,(128, 128))
            y_label_name = y_path[ith].split("/")[-1]
            cv2.imwrite(os.path.join(test_preds_saved_folder, y_label_name), y_label_resize)

            # shutil.copy2(x_path[ith], test_preds_saved_folder)
            # shutil.copy2(y_path[ith], test_preds_saved_folder)

        # 保存预测和标签的对比图
    
    test_y_pred_numpy[test_y_pred_numpy > 0.5] = 1
    test_y_pred_numpy[test_y_pred_numpy <= 0.5] = 0
    test_y_label_numpy[test_y_label_numpy > 0.5] = 1
    test_y_label_numpy[test_y_label_numpy <= 0.5] = 0
    
    test_y_label_numpy = test_y_label_numpy.astype(np.uint8)
    test_y_pred_numpy = test_y_pred_numpy.astype(np.uint8)

    test_scores = scores(test_y_label_numpy, test_y_pred_numpy, 2)

    # print("Test Dice Score: {:.4f}".format( test_score / test_len ))
    print("Scores:")
    print_dict(test_scores)
~~~

